[0.00 --> 6.04]  So this is the stand-up episode two where we talk about all of the greatest things you see going on
[6.04 --> 12.32]  in tech and to get us started we are going to look at everybody's favorite person I believe
[12.32 --> 19.72]  hold on let me pull this up Andy Jassy the CEO of Amazon who has recently been saying a lot of
[19.72 --> 25.80]  things on the internet and this actually does include the following before the pandemic not
[25.80 --> 33.16]  everybody was in the office five days a week every week if you or your child were sick if you had some
[33.16 --> 37.96]  sort of house emergency if you were on the road seeing customers or partners if you needed a day
[37.96 --> 43.04]  or two to finish coding in the more isolated environment people worked remotely this was
[43.04 --> 48.84]  understood and will be moving forward as well but before the pandemic it was not given that folks
[48.84 --> 54.36]  could work remotely two days a week and that will also be true moving forward our expectation is
[54.36 --> 59.14]  that people will be in the office outside of extenuating circumstances like those mentioned
[59.14 --> 64.52]  above and if you have already have remote work exception approved through your s team leader so
[64.52 --> 68.62]  one of those two things is what he's saying so he's kind of building up this case that remote work is
[68.62 --> 74.86]  coming to an end and he even said that we want to operate like the world's largest startup and then
[74.86 --> 81.04]  just a couple days ago on Bloomberg he said the following if you are a culture that invents a lot
[81.04 --> 86.20]  and collaborates a lot some incoherent rambling where he stumbled on some words if you don't have
[86.20 --> 91.62]  people in the office together doing that intent invention it's just meaningfully worse you don't
[91.62 --> 96.00]  invent you don't collaborate the same way you don't connect with each other the same way you don't
[96.00 --> 101.16]  learn the culture the same way and so having people back in the office together more frequently we
[101.16 --> 109.00]  felt very strongly we felt it would be better for customers and the business end quote now Casey you've
[109.00 --> 115.46]  never actually had a real job before and so since since that is the case it how do you feel about
[115.46 --> 120.18]  this whole remote work and devs is it a requirement is it actually something that makes meaningful
[120.18 --> 126.32]  differences or is this just a fabrication of the man trying to hold us down with his real estate prices
[126.32 --> 130.82]  and trying to get these properties and these commercial properties rented as I've been told on reddit
[130.82 --> 137.44]  uh well you know I will say I did I did have a brush with the real job because obviously when I worked at
[137.44 --> 145.22]  rad one of the things that we did do was we we did a there was a very large contract for intel that was being
[145.22 --> 152.22]  done and I got to kind of experience second hand that amazing force of multi-level management and it was
[152.22 --> 157.62]  pretty it was pretty special so I kind of have a I have a vague idea of what goes on but thankfully it was it was
[157.62 --> 163.34]  sort of like you know what what you know like sort of like on a whale watch we kind of see it off the the distance you
[163.34 --> 170.28]  know doing its little breach thing uh I don't have a lot to add to this I I feel like I I wanted to mention
[170.28 --> 175.48]  one thing about that memo and I feel like then you guys should probably have the majority of the
[175.48 --> 181.78]  reaction to this the thing that struck me in that memo is it read almost like someone who was you know
[181.78 --> 188.42]  getting up to give like a speech at a funeral who had been like crying beforehand and was like just
[188.42 --> 193.90]  barely holding it together and just almost got the thing out and then just broke down anyway and the
[193.90 --> 199.64]  reason I say that is because when I read it there's this big long like two paragraph sort of thing in
[199.64 --> 205.20]  there that's like look we're you know we used to be really lean and you know we want to run like a big
[205.20 --> 210.18]  startup and we're going to invent and all these managers are everywhere and they're ruining everything
[210.18 --> 213.90]  and we're going to get rid of that and we're going to come back to the office it's going to be
[213.90 --> 219.46]  awesome right and it sounded like he really believed it like I was wicked into it I'm like
[219.46 --> 224.94]  okay man like you know what you've got a vision you're going for it that's cool but then in like
[224.94 --> 231.30]  the very next paragraph it was like now there are some things like you're going to need to coordinate
[231.30 --> 236.04]  with your s team I have no idea what that is I assume it means a team that's way better than the
[236.04 --> 242.50]  a team like and obviously there are okay it's a tier list they rank all their teams into a tier list
[242.50 --> 248.68]  and they're all s tier size all your team you got to coordinate with your s team obviously uh if you
[248.68 --> 255.22]  have a remote work exception which was all capitalized like that's the thing so it wait he was able to hold
[255.22 --> 260.22]  the like lean startup we're not going to have managers together for like only a few sentences
[260.22 --> 266.48]  and then it went right back to like all of these amazon jargon structural like things and I'm just like
[266.48 --> 271.46]  okay you're you're still just going to have like a bunch of middle minute shirts like you're not really
[271.46 --> 275.92]  fooling me that was what I got out of the memo maybe maybe I'm over reading it but it was hilarious
[275.92 --> 282.70]  how quickly it went back into weird jargon stuff where it was just like uh okay but can Casey can
[282.70 --> 288.46]  a company even escape that the size of amazon right if you have 10,000 engineers like how can you not
[288.46 --> 292.96]  just have tons of middle management right because you're going to have at least how many like if you
[292.96 --> 297.88]  had for every 10 engineers you had one manager that'd be a thousand managers so that means for every
[297.88 --> 302.58]  10 managers you might have a director which would be 100 directors for every 10 directors you have a
[302.58 --> 307.54]  vp you have 10 vps does that mean you have to have like one senior vp for every 10 vps for every
[307.54 --> 312.64]  you know like you could just see like that structure is almost inevitable to kind of form is it possible
[312.64 --> 320.90]  to to avoid that well I mean I guess the question is is it possible to avoid it and do what right I mean
[320.90 --> 326.20]  obviously we all agree that it's possible to avoid it in the sense that you could just not have it the
[326.20 --> 331.38]  question is how effective is it and I guess the one thing I would point out is we do know that you
[331.38 --> 338.52]  can be let's say 500 employees and not have any management uh because obviously valve is like
[338.52 --> 344.40]  massively dominant and makes infinity cash per year they they almost certainly have a massively higher
[344.40 --> 350.68]  per employee uh income for the company than does say an amazon or something like that
[350.68 --> 357.58]  and they don't have that structure right so we do know you could do it with 500 the question is can
[357.58 --> 364.64]  you do it with 5 000 maybe not can you do it with 50 000 maybe not right uh and so there may be a
[364.64 --> 370.60]  natural size at which if you don't go ultra hierarchy there's really nothing you can do
[370.60 --> 376.20]  trash you're you're the only one left of us that actually work at a company that fulfills this kind of
[376.20 --> 381.38]  size and requirement now before I left Netflix Netflix used to be known as this bastion away from
[381.38 --> 386.86]  all the Silicon Valley which was you come there you're a senior engineer you get ownership you just
[386.86 --> 394.06]  go in and you get after it and then 2020 happened COVID happened we must hire younger more green people
[394.06 --> 400.48]  happened we actually brought in a whole group of Amazon management specifically from Amazon then levels
[400.48 --> 406.04]  started happening process started happening uh is this just inevitable trash are you feeling the
[406.04 --> 412.50]  burn of middle management over there I thought that was how trash got hired how dare you first of all
[412.50 --> 421.20]  I want to start this with all opinions on my own and and if my if anyone from my company sees this
[421.20 --> 426.96]  it does not reflect any of their views I'm just gonna protect myself here okay smart very okay I was
[426.96 --> 432.92]  like I was like oh no I was like two password policy like my stuff it got like very tight when he
[432.92 --> 438.38]  brought up when he started introducing me I was like oh I mean I'll say this I've been I've been
[438.38 --> 442.46]  around the block and I've been a part of like some big companies like banking and stuff like that that
[442.46 --> 447.52]  have like way bigger engineering structures um and in my experience to be honest like so I've been from
[447.52 --> 454.64]  big to startups Netflix is kind of like in the middle um I still think they run fairly lean compared
[454.64 --> 460.92]  to like an Amazon obviously like Facebook and all those other big thing companies um so like in that sense
[460.92 --> 465.34]  like for me already seeing like the extreme spectrum of like huge middle management like in banking you
[465.34 --> 470.44]  basically end up in meetings where no one even has the power to make a decision and then you just
[470.44 --> 475.22]  basically keep passing that on and then you ultimately get to the end where whoever can make the decision
[475.22 --> 479.84]  will potentially make the decision in the complete opposite direction of all the other people having
[479.84 --> 486.18]  the meeting and I've seen this time and time again about my previous companies um is it inevitable
[486.18 --> 491.22]  I don't know what I think is going to happen is Amazon is probably going to you know flatten it I
[491.22 --> 496.32]  do like flat the the advantage of having a flatter structure is faster decisions you don't have to go
[496.32 --> 501.62]  through all this bureaucracy bullshit like you as an IC actually have like you feel like you have control
[501.62 --> 506.68]  of what you're doing so I think this is what's going to happen on Amazon but I absolutely think that
[506.68 --> 511.66]  they're just going to backtrack in like three months when everyone and every team just starts building
[511.66 --> 516.74]  things that no one even cares about right if you put like sometimes when you put engineers in in charge
[516.74 --> 521.44]  they usually build what engineers think are important and not necessarily what the customer wants
[521.44 --> 527.24]  and I've seen this basically in every company not even excluding Netflix right where I think this is
[527.24 --> 531.42]  important I have a use case for this and then like you go three months and you're like oh shit we just
[531.42 --> 534.84]  we just built the wrong thing so I think that's actually what's going to happen at Amazon
[534.84 --> 540.76]  um so I guess I guess we'll see I have a lot of other like mean thoughts about like Amazon like
[540.76 --> 546.90]  what is the culture that they're referring to I I feel like my simple size is pretty big I feel like
[546.90 --> 554.16]  everybody I know that either works at Amazon or has left Amazon has completely hated it so I would and
[554.16 --> 558.80]  I actually try to like google like the culture doc before this and like it didn't even show up in like
[558.80 --> 562.52]  in the first results I don't even know what the culture is so I would leave it I would love to know
[562.52 --> 568.06]  like what they would be I believe if I'm not mistaken uh the Amazon culture is that of the
[568.06 --> 573.82]  judge dread culture of mega city one people go in meat comes out like I'm pretty sure that has
[573.82 --> 580.72]  always been the general goal well can you correct me though if I'm wrong here isn't Amazon the company
[580.72 --> 586.40]  where you have like everyone's dog is at work no that'd be more like that was like the old google days
[586.40 --> 590.92]  right that was the old the old that was really just like old silicon valley days I think those days
[590.92 --> 594.96]  have largely passed where everything's just like hey bro we got our dogs at work and it's super cool
[594.96 --> 598.72]  so they're not allowed to do that anymore I don't know if they're allowed or not allowed to bring
[598.72 --> 603.36]  their dog to work at this point I know there's a couple dogs at Netflix there's a few there but there
[603.36 --> 608.14]  wasn't very many okay it was not really considered like a thing people did generally speaking because
[608.14 --> 612.22]  in the early days of Amazon anyway the dogs were everywhere it was just like a dog fest there
[612.22 --> 618.62]  really is this like a well-known fact oh absolutely I knew tons of people at early
[618.62 --> 623.60]  Amazon yeah Trash why do you hate dogs this is our culture it's like it's Amazon's culture we like
[623.60 --> 631.48]  dogs we're not cat people no like dog poop in the elevator as a common thing is that is like early
[631.48 --> 637.58]  Amazon no like not I mean I shouldn't say early early Amazon because there wasn't an elevator at very
[637.58 --> 644.14]  early but but I mean you know at at the tier where they you know you know like early 2000
[644.14 --> 651.76]  and or something like that uh then and uh and so like I've I always thought the return to office
[651.76 --> 656.86]  thing I was like when I saw that part of the memo I'm like gosh I hope there isn't dog poop everywhere
[656.86 --> 661.26]  because that that would be a good argument for staying home as well because that just sounded awful
[661.26 --> 665.88]  especially as a cat person I'm like I don't want dogs everywhere anyway sorry I didn't mean to
[665.88 --> 673.54]  derail that I just I think Amazon I think dog poop I was unaware of the lore of Amazon now TJ you
[673.54 --> 679.42]  actually have been remote working for quite some time now I've been led to believe that remote work
[679.42 --> 687.86]  is actually not possible and produces zero engaged workers is this is this actually how it is well I
[687.86 --> 693.96]  started streaming while I was working remote and then I quit my job so I mean you're asking the wrong
[693.96 --> 699.86]  guy dude don't do not put me he has the poster child of remote workers here
[699.86 --> 708.22]  let's okay it's good for your personal development let's say there's a way to phrase it career
[708.22 --> 714.60]  advancement was high I went from employed with a job my parents kind of understood to unemployed with
[714.60 --> 725.44]  something my parents definitely don't understand oh my I I have a question though for trash trash do you
[725.44 --> 733.02]  think currently the managers at Amazon are solving problems that customers like want because I liked your
[733.02 --> 739.50]  point that I think engineers do tend to like to solve the problems that interest them but I guess like it's kind of
[739.50 --> 745.32]  compared to what I'd be interested if you think like Amazon's current scenario is such that they're
[745.32 --> 750.48]  currently solving the customer problems I feel like in middle management that objective kind of
[750.48 --> 755.54]  disappears and everyone kind of just cares about their name being visible because there's just so many
[755.54 --> 761.32]  layers to the cake that ultimately they just want to make sure that um you know whoever's above them
[761.32 --> 765.36]  knows that they're doing their job and I'm not saying this isn't what's happening at Amazon I've just
[765.36 --> 768.32]  seen this happen personally you're just saying it happens at Netflix is what you're trying to say
[768.32 --> 776.96]  flip you gotta edit that out you gotta flip I swear what if I actually get fired the next week I'm
[776.96 --> 783.34]  like all right I guess I'm just a full-time it would be because of the password that's why it's not this episode
[783.34 --> 788.60]  no but but seriously like when there's just so many like layers of power people just need to impress
[788.60 --> 793.10]  and just have their name there um I mean that's also why you have project managers too it's not
[793.10 --> 797.52]  necessarily the actual management like project managers exist for these specific reasons if you cut
[797.52 --> 801.48]  them out and it's just a manager and they kind of have both the roles I don't know I can't I can't
[801.48 --> 807.52]  say for Amazon but I would give it like a 90 90 chance that they're not really actually thinking
[807.52 --> 812.44]  about customer problems or everyone there's like selfish like there's like self selfishness to a
[812.44 --> 818.44]  degree right um so we'll see I guess we'll find out when they fire all the managers and they make
[818.44 --> 824.02]  nobody happy well the funny thing is they just said all they wanted to do is increase the ratio by 15%
[824.02 --> 829.28]  or something like that it's not even like they're saying we're done with this as a role we no longer
[829.28 --> 834.90]  hire middle managers they're just like we need less and ever you know all of a sudden reddit loves
[834.90 --> 840.22]  middle management I thought that was that was the strangest favorite class like maybe they like
[840.22 --> 845.76]  billionaires less but there's like so few of them right so it's like I thought reddit's most hated
[845.76 --> 851.78]  group was middle managers they just suck the corporate soul they're just useless and then all of a sudden
[851.78 --> 857.90]  it think of the core think of the middle managers oh my goodness they're just pulling up the ladder
[857.90 --> 862.92]  skill ladders being pulled up filling it with just useless MBA so it turns out it actually goes
[862.92 --> 869.18]  billionaires then MBAs then middle management right it was the ordering of reddit hate yeah how do you
[869.18 --> 877.40]  even get to the 15% they're like Jimmy give me a number uh 15% let's go for it yeah I'm sure it was
[877.40 --> 882.54]  highly logical trash okay they they went in there and they just said yeah it's just too many yeah
[882.54 --> 888.80]  all right all right just like about remote work that I think is funny that like a lot of people
[888.80 --> 893.04]  so I'll get canceled again for this one so that'll be fun at least one episode every time an episode
[893.04 --> 898.10]  I'll have to say something that reddit will hate me for which was that even in the announcement
[898.10 --> 903.78]  they mentioned this thing called remote you know work exception which I find funny because basically
[903.78 --> 910.12]  like they're saying if we care enough about you if you're actually a good enough worker we will bend
[910.12 --> 915.88]  over backwards to keep you here so literally like getting called back to office for a bunch of people
[915.88 --> 922.24]  is like just Amazon just saying we only mildly value your work you're not good enough to get an
[922.24 --> 927.06]  exception even at epic where they have literally just one campus where I worked there were like three
[927.06 --> 933.00]  people that still could they they had they somehow got the approval right and why is it they're just so
[933.00 --> 938.58]  valuable to the company so I just love sort of uh like imagining a bunch of reddit people fuming
[938.58 --> 944.58]  that you know oh Joe or Sally over there has the remote work exception and it's not it's like yeah
[944.58 --> 950.42]  dude you haven't done anything for the company well it might be more like a driver's license right it's
[950.42 --> 956.00]  like okay you have to go take a test and they put you in front of a computer and they see like how
[956.00 --> 961.28]  often you click on like Facebook or something and and that's how they know whether they're going to give
[961.28 --> 966.78]  your remote work exception right it's like they they're they know like okay this is a person who
[966.78 --> 972.04]  doesn't get anything done unless there's someone sitting very close to them who can see them screwing
[972.04 --> 978.48]  around and and those people you don't get a remote work exception they just have a series of social
[978.48 --> 983.88]  logins that's all it is it's like now log in with Twitter you're like oh yeah dang okay I guess I log
[983.88 --> 989.72]  on Twitter like sorry you yap too much on the internet you don't have to two factor off to each of the
[989.72 --> 994.04]  social things on your work computer that's how they know they're like right get back in the office
[994.04 --> 1000.34]  get back in well trash would ruin this test because he would know all of his passwords since they're
[1000.34 --> 1004.54]  just one password and it would look like he logs into social media all the time I got at least three
[1004.54 --> 1010.90]  now okay okay all right we're moving up in this world moving up that's trash getting secure
[1010.90 --> 1019.26]  yeah all right geez oh I was not expecting that but I uh I am a pretty big fan of Reddit and the just
[1019.26 --> 1023.90]  the about face I think the thing that's most confusing about Reddit is this there's this idea
[1023.90 --> 1031.12]  of the shadowy cabal that the reason why remote work is ending is because they want uh the offices to
[1031.12 --> 1036.92]  be filled by people who run REITs and so there's like this shadowy cabal that's putting pressure on the
[1036.92 --> 1042.72]  commercial companies on behalf of REITs so they can have better dividend payouts but Amazon owns
[1042.72 --> 1047.92]  its buildings it's too late that's not how it works buddy okay so you don't understand in the
[1047.92 --> 1052.96]  Reddit comments on this thread they've explained it that the reason that they're doing this is because
[1052.96 --> 1060.42]  of corporate real estate okay so we know this must be true because they commented it on Reddit and
[1060.42 --> 1066.12]  they're a real estate expert yeah you're a fool Casey see the thing is is a building that Amazon
[1066.12 --> 1073.04]  owns sitting empty is more expensive and hurtful to the company than a building filled with staff
[1073.04 --> 1077.54]  and maintenance and having everybody in there and treats and all the stuff and micro kitchens and all
[1077.54 --> 1081.92]  those things it's actually cheaper to run the building than to let it stay vacant so it's behooving
[1081.92 --> 1088.62]  Amazon to really screw the people by getting them back in that is some quality Reddit reasoning right
[1088.62 --> 1094.56]  there that makes literally zero sense like they built the skyscrapers for their headquarters
[1094.56 --> 1101.60]  themselves and they own them they are not leaseable buildings they own them they built three giant
[1101.60 --> 1106.48]  balls we call them Bezos's balls if you live here in Seattle have you never seen them they're this
[1106.48 --> 1112.58]  three balls have you been you didn't know about the dogs do you know about the doors the desks made
[1112.58 --> 1118.70]  out of doors you guys you guys don't know any Amazon lore here there's so much Amazon stuff yeah if
[1118.70 --> 1124.38]  you go to downtown Seattle you can go to their campus where they built they built not they had
[1124.38 --> 1131.50]  someone else build and lease they built several giant 40 plus story skyscrapers and as part of the
[1131.50 --> 1138.10]  agreement with the city they had to create something that wasn't horrible like you know the city obviously
[1138.10 --> 1142.82]  you do this kind of stuff you're gonna have to you gotta grease all these palms so they built these
[1142.82 --> 1150.34]  three spherical giant spherical like greenhouses I don't know what uh uh I don't know what you call
[1150.34 --> 1155.86]  them and they put maybe because their name is Amazon I don't know they put like a rainforest in
[1155.86 --> 1160.88]  there there's all these trees and and botanists there are full-time botanists who go around and
[1160.88 --> 1165.46]  maintain all these weird exotic flowers you guys never heard of this no I don't know what you're
[1165.46 --> 1169.82]  talking about I swear to god you're gonna look it up it's all true I'm not making this up yeah all
[1169.82 --> 1173.92]  right well Jeff we'll do a deep dive on Jeff Bezos's balls next week but this week we gotta
[1173.92 --> 1178.46]  stay focused okay we gotta go on to a topic that's near and dear to your heart Casey okay
[1178.46 --> 1187.42]  this right here okay do you see what I am seeing Casey uh yeah I see something yes that my friends
[1187.42 --> 1195.40]  is a high-end state-of-the-art helicopter for Peter Levels IO video game that he's been making with
[1195.40 --> 1199.92]  cursor and if you haven't seen it it's pretty fantastic there's actually a whole upgrade screen
[1199.92 --> 1204.64]  where you can purchase different types of vehicles at the end of the day there's a whole bunch of
[1204.64 --> 1212.38]  sponsors and this has in fact landed Peter Levels to say that he is making $67,000 monthly recurring
[1212.38 --> 1218.86]  revenue of which he actually just updated going all the way up to 72,000 and even in that tweet
[1218.86 --> 1225.80]  more people signed on so I'm kind of seeing something here I'm seeing Peter Levels a novice
[1225.80 --> 1235.00]  game developer powered by AI has made more successful products than the average indie game dev
[1235.00 --> 1241.94]  Casey does it hurt is game dev over are we cooked is this the end of the expert like where what what's
[1241.94 --> 1250.24]  happening here Casey uh no this is total amateur hour and let me explain why so uh if you want to
[1250.24 --> 1257.08]  take a look at how the professionals do this you can see what it really means to have some monthly
[1257.08 --> 1265.94]  income so if for example you rewind the clock and go to cloud imperium games you will notice that
[1265.94 --> 1274.66]  right out of the gate they got people to give them was it 13 million 30 million dollars for stars to
[1274.66 --> 1282.50]  do star citizen and since then with star citizen highly regarded game by without without ever
[1282.50 --> 1291.96]  actually shipping the game over the past 15 years they have now what they have youtube videos that
[1291.96 --> 1296.36]  right they have you well and they and there's an alpha much like levels io has there is like a thing
[1296.36 --> 1301.66]  it doesn't really work much like the levels io one but it's there you can you can go on right
[1301.66 --> 1311.96]  they've uh generated uh half a billion dollars in spend uh total so so no like basically what
[1311.96 --> 1319.06]  you're seeing is an amateur selling sell a non you know an incomplete buggy product right and if you
[1319.06 --> 1324.88]  look at how professionals do that they crush him they're they're so far ahead of so they deliver
[1324.88 --> 1329.06]  later they sell more bugs and they get more money is what you're trying to say way more money and
[1329.06 --> 1334.44]  employ way more people like it's i mean right and it so you can you can see the difference and have
[1334.44 --> 1340.94]  higher production values if you go look at a star citizen alpha the the art is gorgeous right there's
[1340.94 --> 1345.44]  all this stuff in it so you know so i think all we're seeing here is like yep i don't know that
[1345.44 --> 1350.08]  the ai was necessary i mean the thing that he showed kind of looks like you booted up roblox
[1350.08 --> 1354.08]  or something so i don't think you need ai for anything there you could have just done this with
[1354.08 --> 1359.90]  anything uh and so the ai part is not really the the interesting part although i guess i would point
[1359.90 --> 1364.66]  out the ai did give him something which is that probably if he hadn't have been talking about how it
[1364.66 --> 1369.76]  was made with ai no one would have gone and looked at it right so the ai gives you does give you
[1369.76 --> 1375.16]  something and that something is the ability to attract attention because people for some reason
[1375.16 --> 1382.08]  think it's interesting if that makes sense so if i'm just using casey's logic here uh so game devs
[1382.08 --> 1388.68]  they can pull in enormous amounts of money pre-execution and be able to deliver buggy code i mean i i'm
[1388.68 --> 1393.08]  personally just thinking trash dev i think we found a calling for you like if you get fired
[1393.08 --> 1400.44]  it sounds like triple a gaming is right up your alley quadruple a yeah you can make a full true
[1400.44 --> 1405.60]  but true quadruple a game experience if there's anything about not delivering i'm your man i got
[1405.60 --> 1412.78]  you yeah if anything levels like why did he even make the game right that seems kind of like an error
[1412.78 --> 1418.54]  he could have just he could have just had everybody pre-order and then walk away that would have been
[1418.54 --> 1422.80]  so much smarter what was he thinking that's where the money's at because you don't actually have to
[1422.80 --> 1427.28]  execute right but but tj do you think that it's actually just so casey kind of put a little
[1427.28 --> 1431.88]  pressure against it you do you think it's actually like tj you can go with this one do you think it's
[1431.88 --> 1437.56]  actually because he mentioned ai that caused all the ruckus or is it or is there something more
[1437.56 --> 1443.96]  i think it's part of that i think people underestimate levels skill at telling a story
[1443.96 --> 1449.42]  there's like a lot and you know there's lots of people who have more followers than he does i mean he
[1449.42 --> 1454.38]  has a lot of followers they're really engaged with him and everything but like part of it is just
[1454.38 --> 1460.34]  like ai i think it gets some people in the door for sure but like everybody posts an ai thing every day
[1460.34 --> 1465.36]  now i don't really think you know you gotta say like what's the competitive thing that he's doing
[1465.36 --> 1471.94]  differently and i think people underestimate how good of a storyteller levels is and they appreciate
[1471.94 --> 1478.82]  like his candor and like just the way that he tells the story publishes what he's doing where he's
[1478.82 --> 1485.52]  going with different things and so i feel like people are really underestimating that like levels
[1485.52 --> 1491.76]  has a big audience in large part because he's a very good storyteller i'm not saying like as a
[1491.76 --> 1495.44]  like i'm not saying like he's lying you know what i'm saying i'm saying like he tells good stories
[1495.44 --> 1501.54]  people enjoy listening to him and hearing what he has to say so i think that that's a big part of the
[1501.54 --> 1506.84]  success i think he could have built the game potentially like without ai it probably would
[1506.84 --> 1511.42]  have blown up less i do do agree would have probably taken him longer too because there was like a bunch
[1511.42 --> 1517.40]  of stuff that he doesn't have any like domain expertise about at all right like that's not his
[1517.40 --> 1523.02]  normal thing but if he had some other like flashy feature that people thought was fun and interesting
[1523.02 --> 1528.10]  i feel like he could have woven a lot of the same story i mean the main way he's making money is not
[1528.10 --> 1533.10]  people buying skins it's buying advertising right because people are seeing the game so it's not
[1533.10 --> 1537.62]  really they're buying for the game like the money is making is in ads which is i'm not like there's
[1537.62 --> 1544.50]  nothing wrong with that that seems nicer than like uh like dark patterns tricking 12 year olds into
[1544.50 --> 1550.28]  buying upgrades for your game like i'd way rather charge a company for ad space than tricking 12 year
[1550.28 --> 1555.88]  olds into getting mom's credit card right so that seems like roadblocks yeah i wasn't saying anybody in
[1555.88 --> 1560.02]  particular you know i'm unemployed i can't get fired from that i don't think but i want to make it back
[1560.02 --> 1566.94]  on the podcast so um yeah so i think i think there are like elements of like yeah it's ai yeah it's part
[1566.94 --> 1571.32]  of his like large following and all this other stuff but people are underselling how good he is at telling
[1571.32 --> 1577.82]  stories crafting a narrative making it fun and enjoyable to follow along like if he had just only
[1577.82 --> 1583.90]  posted the game at the end i don't think anyone would care it's seeing each of the little building
[1583.90 --> 1588.64]  blocks and he's excited that it's happening that's what's getting people like oh cool i'll go fly
[1588.64 --> 1593.28]  around and then he gets a lot of a lot of traffic that's because he's talking about it in an interesting
[1593.28 --> 1597.74]  and intriguing way like i've clicked on the site i've flown around i wouldn't have done that if levels
[1597.74 --> 1605.32]  wasn't so good at telling stories so one thing i also kind of observed with the with the like sponsor
[1605.32 --> 1611.62]  and the monthly revenue is i don't think people are purchasing it for the chance to really get after
[1611.62 --> 1615.78]  the full audience because he even posts he gets 20 to 50 concurrent viewers i'm not sure if that's
[1615.78 --> 1621.60]  really like the the bang going into that doesn't sound like what you should like what he's actually
[1621.60 --> 1626.04]  or what the companies are expecting to get back out in my head a lot of that is just the fact that
[1626.04 --> 1629.68]  he's going to be tweeting and talking about it and these pictures are going to be flying around and
[1629.68 --> 1635.06]  they get to be associated with the levels io brand is it is that storytelling it is that thing that
[1635.06 --> 1639.36]  makes it so compelling if anything the big thing that this taught me is that people with ai
[1639.36 --> 1644.08]  that don't know how to enter into a domain that they're just like unfamiliar with and it does
[1644.08 --> 1650.84]  have like a rather large steep curve can lightly enter into it and make some level of splash and to
[1650.84 --> 1656.34]  be able to use their kind of maybe disproportionate social weight to be able to make like actually
[1656.34 --> 1661.00]  something that makes some money or become something that's popular that maybe probably like in all
[1661.00 --> 1664.96]  reality probably shouldn't have a plane game that you're just driving around shooting basic bullets like
[1664.96 --> 1669.64]  there's nothing to that game to begin with but it's the fact that you might just see levels io in
[1669.64 --> 1674.28]  the game or he might tweet a picture with you in it right like there's all these like exciting facets
[1674.28 --> 1681.40]  that are completely i guess away from the idea that it is you know just a game that people are buying
[1681.40 --> 1689.38]  i have a question yeah go for it so this might be this might sound pretty basic but to have mrr
[1689.38 --> 1695.22]  doesn't it don't you need like a couple months before you can like determine like like 70 000 mr it
[1695.22 --> 1699.70]  didn't just come out like three weeks ago like how is this recurring and this isn't like a dig on
[1699.70 --> 1703.62]  him this is more for me like understanding like how do you calculate these things this i've seen like
[1703.62 --> 1708.06]  dax like call this out where someone's like i have 100 000 mr but it's only been off three weeks and
[1708.06 --> 1711.84]  those people could just drop off like the next month all right so i'm just curious like how like that
[1711.84 --> 1716.96]  even comes up like with those numbers not saying like he's lying i think levels is great but i was just
[1716.96 --> 1721.84]  curious like when the first when he first dropped that tweet i was like okay like how do you how do
[1721.84 --> 1726.42]  you get that that title there i don't know does that make sense what i'm saying am i dumb i think
[1726.42 --> 1732.12]  this is like a pretty common like sorry i made fun of reddit now i'll make fun of indie hackers like
[1732.12 --> 1737.94]  every dollar that they get goes into recurring for some reason you know like that's not how that works
[1737.94 --> 1744.16]  like a subscription is recurring or like if someone signs a contract that's recurring but like if i
[1744.16 --> 1748.66]  release a course and then on the first day it sells ten thousand dollars i don't have three
[1748.66 --> 1754.56]  hundred thousand dollars of monthly recurring revenue right like 10 10 000 times 30 right i just
[1754.56 --> 1760.84]  i don't have that i sold that much money and then maybe never another course again that is like i don't
[1760.84 --> 1766.24]  know it feels like oh it always just goes in the recurring mrr just stands for money i made this month
[1766.24 --> 1773.98]  like you've just totally disqualified yourself for any future cfo position oh shoot like that
[1773.98 --> 1779.74]  like you have to have return to office now or you're gonna get fired i'm back i'm back
[1779.74 --> 1785.50]  c-suite all over right now dreams of working at enron are down the tubes for you my friend
[1785.50 --> 1794.32]  every dollar made is is booked for the for the full future that is how it works i have one last point
[1794.32 --> 1803.56]  i want to make okay anything i learned from this it was how upset people got about this getting so
[1803.56 --> 1809.10]  much attention um like it just just it was kind of like high school everyone's like they're just kind
[1809.10 --> 1813.24]  of like it almost came off as like jealousy in a sense that like oh he got so much more attention
[1813.24 --> 1819.12]  than what i'm doing over here like i get it but it's just like man i don't know it kind of rubbed me
[1819.12 --> 1824.94]  the wrong way but it was also interesting to see how levels even like responded to like these claims
[1824.94 --> 1829.36]  like oh you don't know like these kind of concepts he's like whatever man i'm just like doing my best
[1829.36 --> 1833.58]  or whatever first like and then he just i i started i started playing it from the beginning and it was
[1833.58 --> 1837.86]  complete trash it was like so bad i couldn't even like move and then i tried it like yesterday and i
[1837.86 --> 1842.90]  was like oh he's like actually making this better which was interesting um which which i think makes the
[1842.90 --> 1848.74]  whole thing better because he's actually trying to make it better um but anyways i saw a lot of a lot
[1848.74 --> 1853.60]  of light painted people in a weird way for me after following this and like their kind of takes on like
[1853.60 --> 1858.60]  instead of like encouraging and like that's kind of cool it's more like you're dumb you don't deserve
[1858.60 --> 1865.26]  this and i'm just like if i had your following i would do the same yeah it's like man just you know
[1865.26 --> 1870.88]  just congratulate him it's pretty cool i don't know i've even answered before but i i also have a
[1870.88 --> 1876.92]  real answer in a sense uh which is that like people for some reason forget like that flappy bird
[1876.92 --> 1886.26]  was like the most popular thing on iphone for you know a good month people seem to think that good
[1886.26 --> 1892.60]  and popular are like have something to do with each other but but they don't like that's not how it
[1892.60 --> 1898.56]  works and so i understand why people would be upset like seeing like oh some guy like you know type
[1898.56 --> 1903.10]  some stuff into an ai and this thing this poop came out that doesn't really work and he got all
[1903.10 --> 1908.30]  this attention for it and i'm i'm you know upset about that but in reality it's like well okay but
[1908.30 --> 1914.82]  that's just kind of how the world works the world like there there is a segment of gamers who care
[1914.82 --> 1921.52]  about quality and you can address that market and there is money there to be made but there's also
[1921.52 --> 1926.88]  a huge market of people who are doing other things and that they're not like assessing
[1926.88 --> 1933.98]  this purchase based on that um and and like to the cloud imperium point for like star citizen there's
[1933.98 --> 1939.38]  also a bunch of people who are you know chasing a dream like they want this big open world start and
[1939.38 --> 1945.94]  they're willing to pay a bunch of money like a dot like a like a you know like a vegas uh crapshoot
[1945.94 --> 1951.02]  because maybe it happens right and and there's all of these other dynamics there and that's just how it
[1951.02 --> 1956.32]  is it's messy that's the game industry it's always been that way it's never been that you just do the
[1956.32 --> 1960.66]  best job and you get all the attention or anything like that so you just have to kind of be okay with
[1960.66 --> 1966.92]  that i certainly don't begrudge anybody any of that uh and uh and yeah like i was joking about
[1966.92 --> 1971.72]  the cloud imperium thing but yeah it's like i kind of said that for a reason which is like
[1971.72 --> 1977.94]  nothing levels ios doing is anything worse than we do in the bigger it right like like this is not
[1977.94 --> 1983.84]  this is not an anomaly this person is not stealing money okay but by the industry standards so just keep
[1983.84 --> 1988.52]  keep that in mind is what i would say in fact i to me it even says something about just like
[1988.52 --> 1993.10]  recently there's been a lot of game flops and there's a lot of things that haven't been working
[1993.10 --> 1998.06]  out if anything what it says to me is that perhaps the gaming industry is having a hard time really
[1998.06 --> 2003.18]  understanding their audience right now and levels understands his audience and is able to break
[2003.18 --> 2008.96]  into an industry that he's not in and do something even if it's just for a moment that say the gaming
[2008.96 --> 2013.84]  industry's had like some pretty massive flops concord included to where it's like hundreds of
[2013.84 --> 2018.54]  millions of dollars just disappear in a single day which is pretty wild to think about like the vast
[2018.54 --> 2023.68]  difference between these two but we're gonna keep on going with the ai because this is the my favorite
[2023.68 --> 2028.16]  segment of the day and i hope everybody had did their has done their homework because we are now
[2028.16 --> 2035.42]  gonna look at the ceo of anthropic and he says the following now getting to kind of the job side of this
[2035.42 --> 2043.04]  um i i i do have a fair amount of concern about this um on one hand i think comparative advantage
[2043.04 --> 2049.34]  is a very powerful tool if i look at coding programming which is one area where ai is making the most
[2049.34 --> 2054.22]  progress um what we are finding is we are not far from the world i think we'll be there in three to
[2054.22 --> 2062.46]  six months where ai is writing 90 of the code and then in 12 months we may be in a world where ai is writing
[2062.46 --> 2072.14]  essentially all of the code so is ai going to be writing essentially all of the code in one year
[2072.14 --> 2078.36]  from today oh gosh tj right off the rip i'm ready yes it will be because people will be able to
[2078.36 --> 2084.44]  generate one billion lines of code in an instant and it will all be sloth but it doesn't matter because
[2084.44 --> 2091.22]  by the metric of who's written almost all of the code it will be ai it will be impossible for me to keep
[2091.22 --> 2097.36]  up i cannot write one billion lines per day it's a fact you know what tj there's actually there there
[2097.36 --> 2101.60]  might be an accidental truth here because he didn't say it technically accidental what do you mean
[2101.60 --> 2107.10]  well what i mean is that i assume from his side he's actually saying that all companies need to adjust
[2107.10 --> 2111.34]  right now like all of your engineers are effectively going to be not as valuable it's actually going to
[2111.34 --> 2115.44]  be the tool that they're selling that happens to be where all the value's at your your your
[2115.44 --> 2120.84]  engineers are really just the cart driver but it's the goods that are really in the cart itself that
[2120.84 --> 2127.44]  you kind of want to purchase but it might just be that tj that is so much overwhelming code going to
[2127.44 --> 2132.26]  be generated that people who are not using that or people that are even editing it are so far behind
[2132.26 --> 2138.10]  by accident he is correct and in 12 months it will be just so large that it'll be like 0.1 percent will
[2138.10 --> 2143.78]  be hand artisanal code and impossible to keep up with now casey i know you love ai uh and so you're
[2143.78 --> 2148.32]  probably going to side with this guy in probably a shorter time frame do you think that you will
[2148.32 --> 2154.46]  be writing your c and your game engine and your optimizations with ai within the next 12 months
[2154.46 --> 2163.48]  oh man uh so you know this the the weird thing is you always pick these like very complicated topics
[2163.48 --> 2171.86]  and then you're like we're gonna get through it in 10 minutes guys uh i have no idea what ai is gonna
[2171.86 --> 2177.98]  do in the future i've said this many times the current kind of ai that they've got is never gonna
[2177.98 --> 2183.34]  do much in my opinion like when i've looked at the current ai that they've got basically what it is is
[2183.34 --> 2189.88]  it's it's it's able to sort of mush stuff together in a way that the code that it's generating shouldn't
[2189.88 --> 2194.72]  probably have existed so it's generating code that a better programmer wouldn't have even had that
[2194.72 --> 2199.06]  layer that's there right they would have done something much better that didn't require the code that
[2199.06 --> 2205.22]  the ai actually put in there so ai right now is not generating very usable code from the standpoint of
[2205.22 --> 2214.28]  actually doing a good job but on the flip side the average programmer in their job is also not
[2214.28 --> 2218.88]  generating that kind of code like they are mostly doing that kind of glue layer stuff that really
[2218.88 --> 2222.64]  shouldn't have been there but it's because you're going to use this library and this high level database
[2222.64 --> 2226.38]  thing and whatever and you're going to mush them together and they're sort of sometimes going to work
[2226.38 --> 2229.58]  and they're going to have a bunch of exploits because the quoting doesn't work and all this
[2229.58 --> 2236.32]  other stuff right and the ai can easily generate that code so when people talk about how much code
[2236.32 --> 2241.74]  is going to be written by ai i'm never quite sure what they mean if they mean ai will eventually get
[2241.74 --> 2248.98]  to the point where it can actually totally do that job i vaguely believe you i don't i can't say for
[2248.98 --> 2252.72]  sure that i think that will happen but i could believe that that would happen in a year
[2252.72 --> 2260.06]  if you mean that the ai is actually going to write any actually new code that's useful like like it's
[2260.06 --> 2264.58]  going to actually do a better job writing this png reader than a human would have done or whatever
[2264.58 --> 2269.50]  i don't believe you because i haven't seen any evidence of that yet it doesn't mean it can't happen
[2269.50 --> 2273.94]  i just think it's going to need like it could happen but it's going to require them to make some
[2273.94 --> 2279.06]  breakthroughs and it's it's impossible for me to predict when breakthroughs will happen maybe the
[2279.06 --> 2282.90]  breakthrough happens next week and then we can have it in a year maybe the breakthrough doesn't
[2282.90 --> 2287.88]  happen for 10 years and then we don't have it for an entire decade and i just don't know right i don't
[2287.88 --> 2291.34]  work in that field so i don't want to make predictions about their breakthroughs so that's
[2291.34 --> 2296.22]  my honest opinion about it um i think you know i wouldn't want to be out there saying that in three
[2296.22 --> 2301.32]  months it's going to write 95 of the code but you know i mean like i said i'm not even sure what that
[2301.32 --> 2306.28]  really is talking about so it's hard for me to say so casey why can't you just embrace the vibe
[2306.28 --> 2309.48]  that's i mean honestly that's what i'm hearing right now is you're just not embracing the vibe
[2309.48 --> 2315.82]  and being the vibe yeah dude i actually feel like a level down right now vibe kick right now i don't
[2315.82 --> 2320.76]  even think i can program for the rest of the day after hearing you talk about this if my ai is down i
[2320.76 --> 2328.60]  can't either i got two i got two points along with casey's thing um the the first one is i have yet to
[2328.60 --> 2335.18]  see like a long-running llm kind of thing where it's not guided by humans there's no expertise involved
[2335.18 --> 2342.82]  where it and we want to say like reduces the entropy of the system does it actually take something
[2342.82 --> 2347.96]  that's complex and make it simpler does it work towards a goal of making it simpler or does it
[2347.96 --> 2354.78]  simply add on things on top and make them more complicated if it can never reduce entropy then well
[2354.78 --> 2359.34]  then my earlier prediction slash joke will come true because it will have to continue generating
[2359.34 --> 2365.14]  billions of lines of code to continue to wrap all of the complicated stuff like until until it
[2365.14 --> 2370.86]  can solve so if it can't do that then uh then i then i don't see human expertise being useless
[2370.86 --> 2375.60]  right which is kind of like what sometimes people pull out from this which is not true like it could
[2375.60 --> 2381.22]  be that the ai writes all the code and my expertise is still very useful right that's the that's a
[2381.22 --> 2387.08]  separate question and then the second one is once uh like anthropic or you know chat gpt or whoever
[2387.08 --> 2393.56]  when they can finally make a chat app better than t3.chat shout out theo right then i'll believe that
[2393.56 --> 2397.88]  their llms are good enough to take my job uh because like why are they not making their own products
[2397.88 --> 2403.00]  good like it's why can they not make a chat app good well there's the there's a related question which
[2403.00 --> 2407.90]  is if you actually thought that you could ship something that could generate all this code why are
[2407.90 --> 2412.64]  you giving it to anybody why don't you just use it to make all of the products yourself and then you
[2412.64 --> 2418.44]  capture all of these giant markets the lie that's sort of underlying it is very clear at that because
[2418.44 --> 2424.40]  you're like oh actually what you want to do is just make something barely good enough that an engineer
[2424.40 --> 2431.36]  might use it and then sell it to them so you clearly don't really have any plans to make this thing
[2431.36 --> 2436.86]  be actually good enough to take their job because they're your customer and you kind of want them to
[2436.86 --> 2443.84]  buy it so you want as many of them as possible so not only do you want them to be buying it and
[2443.84 --> 2448.66]  having needing a human there you don't even want to reduce the number of humans that do it you want
[2448.66 --> 2452.70]  to keep that number as big as possible because that's where your paycheck comes from right yeah
[2452.70 --> 2458.88]  so it's a bit weird yeah i've said before like open ai will never you will never find out that they
[2458.88 --> 2465.02]  have like proper agi whatever that means from a press announcement you will find out when they've
[2465.02 --> 2469.64]  remade your business in an afternoon like that's when you'll know because it will just be a matter
[2469.64 --> 2477.28]  of compute so there's like they're not going to tell you by the way hey microsoft we reinvented you
[2477.28 --> 2484.80]  hey amazon we reinvented you today airbnb we reinvent like they are just going to do that and say congrats
[2484.80 --> 2489.90]  we're the largest quadrillion we're the first ever quadrillion company we are all the companies like
[2489.90 --> 2494.38]  they're not going to give you that shovel they're just going to use it for themselves right yep
[2494.38 --> 2502.78]  i do i do like that idea of of entropy and all that tj where it's just a continual addition
[2502.78 --> 2507.38]  to the code base because we were talking about that casey where we actually walked through some
[2507.38 --> 2513.58]  code and we saw exactly that which is as of right now every single instruction that i gave it was just
[2513.58 --> 2520.14]  additional new lines and layers onto the code base where you could evidently see that and so and also
[2520.14 --> 2526.52]  the t3 chat thing it is so true it's like how it just goes to show the difference between expertise
[2526.52 --> 2532.32]  and pretty good because i would argue that the people working on the ui and stuff at uh open ai at
[2532.32 --> 2537.48]  at cloud any of these they're probably pretty dang good engineers better than us yeah better than us
[2537.48 --> 2544.78]  for sure for real we've already tried and like even with tailwind i'm like like but obviously like
[2544.78 --> 2550.78]  theo's whole thing is making like these uis nice and very very nice and he just went and showed that
[2550.78 --> 2556.04]  he outclassed all of them by himself and so therefore or with one or two engineers or whatever
[2556.04 --> 2560.96]  it is but they don't have this multi-billion dollar budget he he was you know off with a few engineers
[2560.96 --> 2566.00]  probably working on very different wage scale and was able to outcompete them so it does show that
[2566.00 --> 2571.34]  there's like a whole realm of human ingenuity and expertise that is like hyper valuable still at this
[2571.34 --> 2576.14]  point now trash we haven't heard anything from you i know you guys talk too much no i keep hearing
[2576.14 --> 2581.66]  you click around can you shut up with your keys keys clicking yeah i hear that mr clickety clacky over
[2581.66 --> 2585.20]  there i can tell because you're unengaged looking to the side no that's not i'm listening and i'm
[2585.20 --> 2590.58]  trying to find a time to jump in okay then get in it's like double duck you can't wait for double
[2590.58 --> 2595.94]  i know i know okay well this is actually how i am a real stand-up just completely tuned out and just ready
[2595.94 --> 2600.62]  for someone to waiting for the screen to just turn black and i'm like oh the meeting end and then i go do
[2600.62 --> 2606.70]  something else okay so but actually my whole take of this is i'm not very concerned if anyone has been
[2606.70 --> 2611.94]  part of a company that has existed more than three years they know that there's a legacy system that is
[2611.94 --> 2618.98]  completely undocumented nobody knows what does what tribal knowledge out to wazoo there's absolutely no
[2618.98 --> 2626.92]  way that this llm can go in and figure out what this like library did that this engineer did 10 years ago and he
[2626.92 --> 2633.30]  quit like last week and he named all his functions wrong like there's just no way so for those reasons like like i was
[2633.30 --> 2640.88]  born in legacy code like my specialty is to go into do it in the slot and just figure it out yeah yeah you know i'm saying so
[2640.88 --> 2645.16]  so what you're trying to say for those reasons netflix engineers produce complete slop
[2645.16 --> 2649.20]  so we gotta stop saying that we gotta stop saying those words
[2649.20 --> 2650.44]  no no no i'm just saying
[2650.44 --> 2652.20]  x netflix engineers
[2652.20 --> 2653.84]  x netflix engineers
[2653.84 --> 2657.00]  latest full-time streamer
[2657.00 --> 2657.84]  trash dev
[2657.84 --> 2660.88]  can't wait to join the podcast full-time
[2660.88 --> 2661.68]  yeah i'm excited
[2661.68 --> 2662.76]  happy to have you trash
[2662.76 --> 2663.48]  welcome
[2663.48 --> 2666.06]  welcome to the pod
[2666.06 --> 2668.18]  you will be seeing this every week
[2668.18 --> 2668.80]  you all are the worst
[2668.80 --> 2672.32]  but you know what i'm saying though right like
[2672.32 --> 2676.24]  you've all been part of legacy code that's just like pure tribal knowledge just like it's insane
[2676.24 --> 2680.28]  so like i haven't seen like an actual case of that happening i know like meta said they fired
[2680.28 --> 2684.42]  a bunch of people so maybe they're they got it to work internally i don't know
[2684.42 --> 2690.24]  um but for like apps that you're using like open source technology and all that stuff i think it'd be a
[2690.24 --> 2695.22]  lot easier for ai to write those apps probably because they're well documented lots of code bases to
[2695.22 --> 2700.56]  reference probably but like you know for a company that's not netflix that's also big you know i'm
[2700.56 --> 2706.02]  saying like they there's just no way in my mind but if it happens you know i'm more than happy to
[2706.02 --> 2706.98]  join the pod full-time
[2706.98 --> 2714.64]  yeah i do think like i'm not saying it's never gonna happen it's just when the prediction is like
[2714.64 --> 2719.62]  three months from now that's like crazy that's really fast like
[2719.62 --> 2726.48]  like they know we still do like flat file transfers for banks in the u.s and that's how like
[2726.48 --> 2733.24]  trillions of dollars gets trained like it's not like they're fdping files at night time
[2733.24 --> 2740.46]  that's how the banking system works we're expecting that nobody at the bank is gonna be writing code by
[2740.46 --> 2744.94]  hand at the end of six months they won't even be legal to use ai in these code bases still
[2744.94 --> 2750.70]  there was a news report recently that said that like aerospace oh sorry the banking aerospace finance
[2750.70 --> 2756.60]  uh medical like almost all of them have like pretty strict do not use llm like some of them don't
[2756.60 --> 2760.92]  but there is like a whole bunch of like you can't give away any of our competitive secrets you cannot
[2760.92 --> 2765.04]  send any of this so it's like there's entire industries that are just like completely resilient
[2765.04 --> 2771.34]  today government this idea government that's like five out of almost that's like 80 percent of coding
[2771.34 --> 2779.00]  i just named and they can't use it yep yeah i'm not scared go go casey what were you gonna say
[2779.00 --> 2783.14]  i was just gonna say i saw a news report recently and i don't know i mean it was a news report so
[2783.14 --> 2790.30]  who knows how accurate it was but it said something like there are 3600 separate programs that need to
[2790.30 --> 2795.96]  be run and communicate with each other to administer social security currently much of which is written
[2795.96 --> 2802.38]  in cobalt apparently right and so i'm just like okay like that's happening now right and i don't know
[2802.38 --> 2807.68]  how well the how good these llms are trained up on on the various different incarnations of cobalt but like
[2807.68 --> 2814.00]  that would be an interesting challenge it's like hey can you can you redo any of this uh but so far
[2814.00 --> 2818.42]  we just haven't seen that like we haven't seen people demonstrating that these things are able to
[2818.42 --> 2823.96]  do much undirected work by themselves and even the directed work tends to be very buggy and strange
[2823.96 --> 2831.28]  so i don't know it just maybe they're gonna cross some barrier soon but well casey you may not you may
[2831.28 --> 2835.36]  not love this answer that i'm about to drop on you but darpa it's been researching a project called
[2835.36 --> 2841.72]  tractor and if you're unfamiliar with tractor converting all that insecure unsafe old man
[2841.72 --> 2850.04]  yelling at cloud c into the new kid on the block rust making it fabulous and fantastic all at the
[2850.04 --> 2855.36]  exact same time there you go they probably saw the word cargo and they're like that's something we
[2855.36 --> 2862.82]  understand all right cargo road they know cargo road that's facts all right i'm gonna give trash
[2862.82 --> 2865.40]  dev the last word trash what do you have to say
[2865.40 --> 2873.36]  if you only know tailwind you're gonna get replaced by ai if you know tailwind or if you don't
[2874.30 --> 2882.40]  if you only know tailwind oh okay good oh very good luck very good take well all right why am i
[2882.40 --> 2886.42]  getting i got the last one last time well just because you're not talking a lot and you're kind
[2886.42 --> 2891.60]  of just a little bit lame you're trash all doing talking no no you guys you're like actually
[2891.60 --> 2896.62]  wanted to address your whiteboard that is so awesome wait is the team the team dev is fake
[2896.62 --> 2902.28]  everything else is real okay be like levels you miss 100 of the shots you don't take michael scott
[2902.28 --> 2908.94]  i'm dropping an ai game don't you worry man you just wait you just wait all right and then of
[2908.94 --> 2914.58]  course the last comment from the top shelf itself juniors not gaining experience will cause a low
[2914.58 --> 2918.90]  supply of senior plus ai will always struggle with breaking down business requirements and
[2918.90 --> 2924.26]  translating to something useful do you think fun kind of thought exercise do you think i know sorry
[2924.26 --> 2927.32]  trash i know i said you had the last word i'm just kidding i don't want you to have the last word
[2927.32 --> 2932.36]  anymore i'm gonna let casey have it uh casey do you think we're gonna enter into a world in which
[2932.36 --> 2938.78]  there's gonna be like the zero mid-level engineer that causes some sort of really wild
[2938.78 --> 2945.96]  disproportional problem in our industry why are you trash was the person perfect person and that
[2945.96 --> 2950.82]  i've never worked at one of these companies well how are you how are you asking me because i'm
[2950.82 --> 2955.70]  at the end of the episode i stopped listening because he said you had the last word so i don't
[2955.70 --> 2962.14]  even know what the question said if i'm being honest take us to black take us out i was like
[2962.14 --> 2968.26]  oh the meeting's over all right all right well hey the name hey by the way this is called the
[2968.26 --> 2974.00]  stand-up so i hope that you appreciate it like subscribe also go follow trash on twitter it's in
[2974.00 --> 2979.12]  the bio tj i also have your twitter tj streams by the way in case you don't know and computer
[2979.12 --> 2985.12]  enhance.com to view all of casey if you don't want to become irrelevant in the day of relevancy
[2985.12 --> 2987.38]  check out computer enhance.com
